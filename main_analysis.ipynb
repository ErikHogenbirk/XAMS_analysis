{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "filename    = 'D:/Documenten/PhD/Data/run6_hdf/run-6_measurement-012.hdf5'\n",
    "file_format = 'hfd5'\n",
    "loglevel    = 'DEBUG'\n",
    "peak_types  = [b's1', b's2', b'unknown', b'noise', b'lone_pulse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# We get a log file\n",
    "import logging\n",
    "log = logging.getLogger('XAMS_analysis')\n",
    "log.setLevel(loglevel)\n",
    "# Notebookloader is needed to import ipython notebooks as python modules.\n",
    "# Notebookloader prompts a warning, but it seems to work fine\n",
    "# TODO Perhaps we need to reconsider what functions we actually need and put them in a regular python script?\n",
    "import logging\n",
    "import NotebookLoader\n",
    "import Function_definitions as fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font', size=16)\n",
    "import h5py\n",
    "import units\n",
    "from recarray_tools import append_fields\n",
    "\n",
    "# Optional progress bar\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    log.debug(\"You don't have tqdm, I can't give you a nice progress bar...\")\n",
    "    def dummy(*args,**kwargs):\n",
    "        return args[0]\n",
    "    tqdm = dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Load the data\n",
    "##\n",
    "log.debug(\"Now loading %s (file format=%s)...\" % (filename, file_format))\n",
    "\n",
    "# Slurp peaks and events into memory\n",
    "# WARNING: For a large dataset, use pax to remove big low-level fields first\n",
    "# (area_per_channel, does_channel_contribute, does_channel_have_noise)\n",
    "try:\n",
    "    # Load the file using pax 3's IO code\n",
    "    # This supports any format pax can currently produce\n",
    "    from pax.formats import flat_data_formats\n",
    "    ioformat = flat_data_formats[file_format]()\n",
    "    ioformat.open(filename, 'r')\n",
    "    events = ioformat.read_data('Event')\n",
    "    peaks = ioformat.read_data('Peak')\n",
    "    ioformat.close()\n",
    "   \n",
    "except ImportError:\n",
    "    log.debug(\"You don't have pax 3 installed, falling back to HDF5-specific code...\")\n",
    "    import h5py\n",
    "    f = h5py.File(filename)\n",
    "    events = f.get('Event')[:]\n",
    "    peaks = f.get('Peak')[:]\n",
    "    f.close()\n",
    "\n",
    "log.info(\"Loaded %s, containing %d peaks (%0.2f MB RAM) and %d events (%0.2f MB RAM)\" % (\n",
    "    filename, len(peaks), peaks.nbytes/10**6, len(events), events.nbytes/10**6))\n",
    "if len(events) == 0:\n",
    "    raise ValueError(\"You don't have any events in this dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS (EH)\n",
    "# Loop over peaks and redefine the classification\n",
    "# TODO get this to work\n",
    "# # At the moment, we just use the default from the processer\n",
    "# s1_cut    = (peaks['type'] == b's1')\n",
    "# s2_cut    = (peaks['type'] == b's2')\n",
    "# other_cut = np.logical_not(s1_cut | s2_cut)\n",
    "\n",
    "# #peaks = append_fields(peaks,'true_type',np.zeros([len(peaks)],dtype=np.str))\n",
    "\n",
    "# n_peaks = len(peaks)\n",
    "# n_s1_before = len(peaks[peaks['type'] == b's1'])\n",
    "\n",
    "# for pk in peaks:\n",
    "#     if pk['type'] == b's1':\n",
    "#         pk['true_type'] = 's1'\n",
    "    \n",
    "# peaks[s2_cut]['type']\n",
    "# log.debug('Before reclassification: %.2f%% of the peaks is an S1' % (n_s1_before/n_peaks*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append fields to the event and peak list. Only the ones that can be directly determined from the events lists\n",
    "\n",
    "# full range: the total time of the peak.\n",
    "peaks = append_fields(peaks, 'full_width', (peaks['right'] - peaks['left'] + 1)*fn.dt)\n",
    "peaks = append_fields(peaks,'mid',peaks['left']*fn.dt + 0.5* peaks['full_width'])\n",
    "\n",
    "# Recalculate area fraction top because of wrong ordering of PMTs\n",
    "peaks['area_fraction_top'] = peaks['area_per_channel'][:,3] / peaks['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group peaks by event\n",
    "peaks_per_event = fn.group_by(peaks, 'Event')\n",
    "#assert len(peaks_per_event) == len(events) # Raise error if false\n",
    "\n",
    "# Add total number of peaks\n",
    "events = append_fields(events,\n",
    "                       'n_peaks',\n",
    "                       np.array([len(x) for x in peaks_per_event]))\n",
    "\n",
    "# Add number of individual peak types\n",
    "for pt in peak_types:\n",
    "    events = append_fields(events,\n",
    "                           'n_'+pt.decode(),\n",
    "                           np.array([len(x[x['type'] == pt]) for x in peaks_per_event]))\n",
    "# Add number of BIG peaks (mainly S2 is important). Use to cut pileup / double scatters    \n",
    "    events = append_fields(events,\n",
    "                           'n_big_'+pt.decode(),\n",
    "                           np.array([len(x[(x['type'] == pt) & (x['area'] >= 100)]) for x in peaks_per_event]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Select events with >=1 S1 and >=1 S2\n",
    "# Necessary step for next cell\n",
    "##\n",
    "n_before = len(events)\n",
    "cut = (events['n_s1'] >= 1) & (events['n_s2'] >= 1)\n",
    "events = events[cut]\n",
    "peaks_per_event = [x for i, x in enumerate(peaks_per_event) if cut[i]]\n",
    "\n",
    "log.debug(\"%0.2f%% of events have >=1 S1 and S2, keeping only those.\" % (100*len(events)/n_before))\n",
    "if((100*len(events)/n_before)<50):\n",
    "    log.warning(\"Only %0.2f%% of events have >=1 S1 and S2, keeping only those.\" % (100*len(events)/n_before))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Add s1_... and s2_... fields to event\n",
    "# This way you can access all properties of the main S1 and S2 directly from the event\n",
    "# TODO add peak area per channel\n",
    "##\n",
    "ignore_fields = ['Event', 'Peak', 'type',\n",
    "                 # recfunctions have trouble with subarrays...\n",
    "                 'does_channel_contribute', 'does_channel_have_noise', 'area_per_channel']\n",
    "for pt in (b's1', b's2'):\n",
    "    main_peaks = []\n",
    "    for pks in tqdm(peaks_per_event, desc='Selecting %ss' % pt.decode()):\n",
    "        peaks_of_this_type =  pks[pks['type'] == pt]\n",
    "        main_peaks.append(\n",
    "            peaks_of_this_type[\n",
    "                np.argmax(\n",
    "                   peaks_of_this_type['area']\n",
    "                )\n",
    "            ])\n",
    "    main_peaks = np.array(main_peaks)\n",
    "    assert len(main_peaks) == len(peaks_per_event)\n",
    "\n",
    "    # Add s1_... and s2_... fields\n",
    "    for fn in main_peaks.dtype.names:\n",
    "        if fn in ignore_fields:\n",
    "            continue\n",
    "        events = append_fields(events,\n",
    "                               \"%s_%s\" % (pt.decode(), fn),\n",
    "                               main_peaks[fn])\n",
    "        \n",
    "if(len(peaks['type']==b'NaI') > 0):\n",
    "    log.debug('Found external NaI, will add those properties!')\n",
    "    main_peaks = []\n",
    "    for pks in tqdm(peaks_per_event, desc='Selecting NaI pulses'):\n",
    "        peaks_of_this_type =  pks[pks['detector'] == b'NaI']\n",
    "        main_peaks.append(\n",
    "            peaks_of_this_type[\n",
    "                np.argmax(\n",
    "                   peaks_of_this_type['area']\n",
    "                )\n",
    "            ])\n",
    "    main_peaks = np.array(main_peaks)\n",
    "    assert len(main_peaks) == len(peaks_per_event)\n",
    "\n",
    "    # Add NaI_... fields\n",
    "    for fn in main_peaks.dtype.names:\n",
    "        if fn in ignore_fields:\n",
    "            continue\n",
    "        events = append_fields(events,\n",
    "                               \"NaI_%s\" % fn ,\n",
    "                               main_peaks[fn])\n",
    "else:\n",
    "   log.debug('No NaI found, so just TPC channels added.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add drift time\n",
    "events = append_fields(events, 'drift_time', events['s2_hit_time_mean'] - events['s1_hit_time_mean'])\n",
    "# Drift time is here from hit time mean to hit time mean. Its the mean of the hit maximum weighted by area.\n",
    "# This DOES introduce a constant, but it's probably a very stable quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# That was the main analysis code! Now we get a couple of example examples of plots\n",
    "# Maybe we should move this to some other file?\n",
    "#\n",
    "#\n",
    "# Examples: - a histogram with legend and a double scale\n",
    "#           - a scatterplot with coloured scale\n",
    "#           - a density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a cut. Examples given: cut away negative drift time, take dirft time slice or cut events with more than 2 big S2s\n",
    "# cut = (events['drift_time'] > 0 * units.us)\n",
    "# cut = (events['drift_time'] > 30 * units.us) & (events['drift_time'] < 40 * units.us)\n",
    "cut = events['drift_time']>-1000000000\n",
    "log.info('Cut acceptance: %.2f%%' % (len(events[cut])/len(events)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot number of S2s for each waveform, and also the number of BIG S2s.\n",
    "plt.hist(events['n_big_s2'],bins=9,range=(0,8),histtype='step',label='Big S2s')\n",
    "plt.hist(events['n_s2'],bins=9,range=(0,8),histtype='step',label='Any S2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drift time v. S2 width\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(events[cut]['drift_time'] / units.us, events[cut]['s2_full_width'] / units.us,\n",
    "            marker='.', edgecolor='None', alpha=1, s=10, \n",
    "            c=np.log10(events[cut]['s2_area']))\n",
    "# Alpha: opacity (0: transparent)\n",
    "# s = size of marker (A.U.)\n",
    "plt.xlim(0,80)\n",
    "plt.ylim(0,30)\n",
    "plt.xlabel('Drift time (us)')\n",
    "plt.ylabel('S2 width (right-left, us)')\n",
    "plt.colorbar(label='log10 S2 area (pe)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(events['drift_time'],bins=100,range=(0,70000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hexbin(events['drift_time']/units.us,events['s2_area'],extent=[0, 70, 100, 15000],gridsize = 100)\n",
    "# See also: plt.pcolor (square bins)    pcolormesh (in comb with np.hist2d)\n",
    "plt.xlabel('Drift time (us)')\n",
    "plt.ylabel('S2 area (right-left, us)')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nice_plots import ColoredScatterPlot, DensityPlot\n",
    "# Did not get y log scale to work yet\n",
    "# TODO do this\n",
    "DensityPlot(events, dataset_name='events', x='drift_time', y='s2_area',x_range=(0,70000),y_range=(1000,200000)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hexbin(events['drift_time']/units.us,events['s1_area_fraction_top'],extent=[0, 70, 0, 0.4],gridsize = 200)\n",
    "plt.xlabel('Drift time (us)')\n",
    "plt.ylabel('S1 area fraction top')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.hexbin(events['drift_time']/units.us,events['s1_area'],extent=[0, 70, 0, 1000],gridsize = 200)\n",
    "plt.xlabel('Drift time (us)')\n",
    "plt.ylabel('S1 area')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drift_cut = (events['drift_time'] > 20 * units.us) & (events['drift_time'] < 30 * units.us)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(events[drift_cut]['s1_area'],bins=100,range=(0,1000))\n",
    "plt.xlabel('S1 area (p.e)')\n",
    "plt.ylabel('Events/bin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supercut = (events['drift_time'] > 20 * units.us) & (events['drift_time'] < 40 * units.us) & (events['s1_area'] > 0)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hexbin(events[supercut]['s1_area'],events[supercut]['s2_area'],extent = [0,400,0,20000],gridsize = 100,bins='log')\n",
    "plt.xlabel('S1 area (pe)')\n",
    "plt.ylabel('S2 area (pe)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine electron lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestep = 2 * units.us\n",
    "starttime = 10 * units.us\n",
    "endtime  = 50 * units.us\n",
    "# Array of center times of bin\n",
    "times =np.array([ time + 0.5*timestep for time in np.arange(starttime,endtime,timestep)])\n",
    "# list of cuts for all these bins\n",
    "timebins = [ (events['drift_time'] > time) & (events['drift_time'] < time + timestep) \n",
    "                                            for time in np.arange(starttime,endtime,timestep) ]\n",
    "# Array of average for this cut\n",
    "avgs = np.array([np.average(events[timebins[i]]['s2_area']) for i in range(int((endtime-starttime)/timestep)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Should show a decreasing trend\n",
    "plt.scatter(times / units.us,avgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We fit a power of e to this...\n",
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b):\n",
    "    return a * np.exp(-(1/b) * x)\n",
    "popt, pcov = curve_fit(func, times,avgs,p0 = [12000.,2 * units.us])\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "log.info('Determined electron lifetime: %.2f +/- %.2f us.' % (popt[1]/units.us,perr[1]/units.us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And plot it! \n",
    "# TODO add a quantity: scaled S2\n",
    "fitx = np.linspace(0,15 * units.us,61)\n",
    "fity = func(fitx,popt[0],popt[1])\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.scatter(times/units.us,avgs)\n",
    "plt.plot(fitx/units.us,fity)\n",
    "plt.xlim(0,20)\n",
    "plt.ylim(0,13000)\n",
    "plt.xlabel('Drift time (us)')\n",
    "plt.ylabel('S2 area (p.e.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nice_plots import ColoredScatterPlot, DensityPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ColoredScatterPlot(events[cut], dataset_name='events', y='s2_full_width', z='s2_hit_time_std',x='drift_time',\n",
    "                   y_range=(0,40*10**3), x_range=(0*10**3,80*10**3), z_range=(0,1000), \n",
    "                   ).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DensityPlot(events[cut], dataset_name='events', x='s2_left', y='s2_right', count_logscale=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ColoredScatterPlot(events[cut], dataset_name='events', x='drift_time', y='s2_full_width', z='n_s2',\n",
    "                   y_range=(0,80000),z_range=(0,5)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ColoredScatterPlot(events,dataset_name = 'events',x='s1_area', y='s2_area',z='drift_time',\n",
    "                  x_logscale=False,y_logscale=False,\n",
    "                  x_range=(0,1000),y_range=(0,40000), grainsize=3, grainalpha=0.5).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
